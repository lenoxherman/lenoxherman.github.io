{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PerceptronOptimizer' object has no attribute 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/lenoxherman/lenoxherman.github.io/Working Blogs/Blog5.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lenoxherman/lenoxherman.github.io/Working%20Blogs/Blog5.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# perform a perceptron update using the random data point\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lenoxherman/lenoxherman.github.io/Working%20Blogs/Blog5.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m opt\u001b[39m.\u001b[39mstep(x_i, y_i)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lenoxherman/lenoxherman.github.io/Working%20Blogs/Blog5.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(opt\u001b[39m.\u001b[39;49mloss)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lenoxherman/lenoxherman.github.io/Working%20Blogs/Blog5.ipynb#W1sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m max_iterations \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PerceptronOptimizer' object has no attribute 'loss'"
     ]
    }
   ],
   "source": [
    "from perceptron import Perceptron,perceptron_data, PerceptronOptimizer\n",
    "import torch\n",
    "\n",
    "X, y = perceptron_data()\n",
    "p = Perceptron() \n",
    "opt = PerceptronOptimizer(p)\n",
    "\n",
    "loss = 1.0\n",
    "max_iterations = 1000\n",
    "\n",
    "# for keeping track of loss values\n",
    "loss_vec = []\n",
    "\n",
    "n = X.size()[0]\n",
    "\n",
    "while loss > 0 and max_iterations > 0: \n",
    "    \n",
    "    # not part of the update: just for tracking our progress    \n",
    "    loss = p.loss(X, y) \n",
    "    loss_vec.append(loss)\n",
    "    \n",
    "    # pick a random data point\n",
    "    i = torch.randint(n, size = (1,))\n",
    "    x_i = X[i,:].squeeze()\n",
    "    y_i = y[i]\n",
    "\n",
    "    \n",
    "    # perform a perceptron update using the random data point\n",
    "    opt.step(x_i, y_i)\n",
    "    max_iterations -= 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234567)\n",
    "\n",
    "# initialize a perceptron \n",
    "p = Perceptron()\n",
    "opt = PerceptronOptimizer(p)\n",
    "p.loss(X, y)\n",
    "\n",
    "# set up the figure\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 5)\n",
    "fig, axarr = plt.subplots(2, 3, sharex = True, sharey = True)\n",
    "markers = [\"o\", \",\"]\n",
    "marker_map = {-1 : 0, 1 : 1}\n",
    "\n",
    "# initialize for main loop\n",
    "current_ax = 0\n",
    "loss = 1\n",
    "loss_vec = []\n",
    "\n",
    "while loss > 0:\n",
    "    ax = axarr.ravel()[current_ax]\n",
    "\n",
    "    # save the old value of w for plotting later\n",
    "    old_w = torch.clone(p.w)\n",
    "\n",
    "    # make an optimization step -- this is where the update actually happens\n",
    "    # now p.w is the new value \n",
    "    i, local_loss = opt.step(X, y)\n",
    "\n",
    "    # if a change was made, plot the old and new decision boundaries\n",
    "    # also add the new loss to loss_vec for plotting below\n",
    "    if local_loss > 0:\n",
    "        plot_perceptron_data(X, y, ax)\n",
    "        draw_line(old_w, x_min = -1, x_max = 2, ax = ax, color = \"black\", linestyle = \"dashed\")\n",
    "        loss = p.loss(X, y).item()\n",
    "        loss_vec.append(loss)\n",
    "        draw_line(p.w, x_min = -1, x_max = 2, ax = ax, color = \"black\")\n",
    "        ax.scatter(X[i,0],X[i,1], color = \"black\", facecolors = \"none\", edgecolors = \"black\", marker = markers[marker_map[y[i].item()]])\n",
    "        # draw_line(w, -10, 10, ax, color = \"black\")\n",
    "        ax.set_title(f\"loss = {loss:.3f}\")\n",
    "        ax.set(xlim = (-1, 2), ylim = (-1, 2))\n",
    "        current_ax += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ code copied form notes to draw a line seperating the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
