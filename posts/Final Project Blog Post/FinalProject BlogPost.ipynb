{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Final Project Blog Post\n",
    "author: Lenox Herman\n",
    "date: May, 14 2024\n",
    "bibliography: bibliograph.bib\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL PROJECT BLOG POST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "Navigating tipping etiquette at restaurants or shops can be challenging due to inconsistencies across different locations and cultures. In our project, we aimed to analyze the tipping behavior following meals at restaurants. Specifically, we sought to investigate whether various factors, such as gender or party size, influenced tip amounts. To address this issue, we employed predictive models, those being linear regression, decision tree classifier, and random forest classifier, to estimate the expected tip for each individual based on the given variables. We ran these models simply on the data and then with combinations of different columns/attributes. The overall results on our testing data was a score accuracy of about 40% and with signs of overfitting.\n",
    "\n",
    "https://github.com/lenoxherman/Tippers/blob/main/ProjectFinal.ipynb\n",
    "https://github.com/lenoxherman/Tippers/blob/main/GDO.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In the social dance of dining out, tipping is impossible to navigate and often adds stress and confusion to your dining experience. The custom of tipping, ingrained in many cultures, serves as a form of appreciation for service rendered, yet navigating the nuances of tipping etiquette remains inconsistent across locations and cultures.\n",
    "\n",
    "Scholars have attempted to uncover what factors influence tipping behavior, looking into an array of variables from physical attractiveness and service quality to demographic factors like age, race, and gender. Lynn (2000) set up their study at a Mexican restaurant in Houston, Texas, scrutinizing the impact of physical attractiveness, service quality, self-monitoring, and gender on tipping behavior. Age and ethnicity were also collected but weren’t used in synthesizing the data. For self-monitoring, the servers were asked to fill out a survey assessing their strengths and weaknesses, including categories such as attentiveness and friendliness. Photographs of the participants were taken, and then a panel of 10 judges, 5 male and 5 female, assessed their physical attractiveness. Each server's tips were then recorded, making sure that participants had equal amounts of evening shifts and day shifts. The findings of the study showed that tips given during daytime shifts, aka during lunch, did not hold any significant findings. Attractive servers were given higher percent tips than unattractive servers. However this only applied to female servers, not male servers. There was no effect of attractiveness on percent tips for male servers. Also, servers who had more confidence in their abilities and rated themselves higher on the survey also had higher percentage tips. \n",
    "\n",
    "Jewell (2008) contributed to this body of knowledge by researching the demographic factors in tipping behavior, despite the potential introduction of biases. In this study 97 individuals were evaluated as customers at a restaurant and the waitresses were actors. They looked at interactions between the patron and the servers, evaluating factors like age, race, mealtime, gender, alcohol consumption, and interpersonal touch connection. Overall the study found that surprisingly younger populations left higher tips than the middle age or the elderly. The biggest predictor of tipping behavior was race, the tip average for a black waiter was 7% lower than that of a white waiter. However, white diners also tip more than black diners as well. \n",
    "\n",
    "Lastly, diners who drank alcohol actually tipped less than those who did order an alcoholic beverage. Adding to this research, Cho (2014) dissected the multifaceted dynamics of tipping behavior, examining variables such as bill size, party size, and patron gender. Business students at an urban university were asked to keep a tipping log, keeping track of where they ate, when, and what tip they left behind. Contrary to the Jewell study, they found a positive relationship between tip amounts and whether or not the party ordered alcohol. They established a relationship between tip size mealtime and bill size, with dinner and bigger bill size tipping more. Lastly, they established a connection between gender and tipping amounts, finding that female costumes often tipped higher. \n",
    "\n",
    "As you can tell, the empirical evidence is contradictory and confusing. Factors that are proved significant in one study, their inverse is proved true in the next. The studies all emphasize the importance of setting and context when tipping and the high variability in tipping behavior can be explained by the social norms and context dependent decisions being made. \n",
    "\n",
    "Given the fragmented nature of empirical evidence surrounding tipping behavior, our project seeks to address this complexity by employing predictive modeling techniques. Focusing on tipping behavior following meals at restaurants, we aim to analyze the influence of factors like gender and party size on tip amounts. Through this approach, we endeavor to provide a more nuanced understanding of tipping etiquette, moving beyond anecdotal observations to uncover underlying patterns and dynamics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values Statement\n",
    "The potential users for our project we imagined would be restaurants, or in general, business owners as well as service staff such as waiters and waitresses. Others who might be affected by this project include the restaurant or business customers, the community surrounding the restaurant, and researchers to name a few.\n",
    "\n",
    "As mentioned, the idea behind our project was for business owners who rely on tips as well as waiters/waitresses to be able to use the information and results to their advantage to get more tips and provide customers a better environment at restaurants. The results could help them make strategic decisions on pricing and staffing. Additionally, this project could be beneficial to consumer researchers and those studying predictive modeling because they can take the findings or get ideas from this project to model more research. Others who might be affected by our project include the customers who attend these restaurants as they might be able to benefit from the improved restaurant quality, or they can also be negatively impacted by being exploited by businesses. The communities where the restaurants are located could also be socio-economically impacted because with improved dining services comes increase in service and menu prices, thus, affecting their ability to eat at the restaurants near them.\n",
    "\n",
    "Our personal reason for choosing this project was because we were curious in finding out what factors influence tipping behaviors in restaurants. We wanted to uncover patterns that would allow restaurant owners to make informed decisions for their restaurant. Furthermore, we wanted to apply the knowledge we gained in class to a real-world data set. We believed exploring this dataset and running predictive models on it would bestow us the opportunity to practice our data analysis skills, data processing, and classification skills. \n",
    "\n",
    "I believe the world of restaurants and businesses that rely on tips would be a better place with this technology as long as they do not take advantage of their customers and make them tip unfair amounts. \n",
    "\n",
    "The world in general will also be more equitable as restaurant staff will be making the income they should if it is a restaurant that has great service for guests. However, there might be unpeaceful situations such as if there are gender biases found and restaurants exploit this information. There will also be less joy if restaurants decide to up their prices for improved customer service and the lower socio-economic families that lived around the restaurant can no longer afford to eat there. It is difficult to say we are sure that this implementation will benefit the world because there will always be groups who get the short end of the stick. However, it is also unfair to say it would make the world a worse place because for the people it does benefit, it will improve their lives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materials and Methods\n",
    "\n",
    " Our data\n",
    "\n",
    "The data was collected from a dataset website known as Kaggle and the collaborator of the dataset is Sakshi Satre (Sat Tips Dataset, 2024). This dataset is used for visualizations in data analysis and it contains information about different factors of customers in a restaurant, such as the total bill amount, tip amount, gender, whether the customer is a smoker or not, the day of the week, time of day (lunch or dinner), and the size of the party. Below are the descriptions of each of these factors as written in the dataset: \n",
    "\n",
    "total_bill: This attribute represents the total amount of the bill paid by the customer, including the cost of the meal, taxes, and any additional charges.\n",
    "\n",
    "tip: This attribute denotes the amount of tip left by the customer. It is typically calculated as a percentage of the total bill and is often discretionary. (This helped form our target value)\n",
    "\n",
    "sex: This attribute indicates the gender of the customer. It could be either male or female.\n",
    "      \n",
    "smoker: This attribute indicates whether the customer is a smoker or a non-smoker. It's a categorical variable with two possible values: \"Yes\" for smokers and \"No\" for non-smokers.\n",
    "      \n",
    "day: This attribute represents the day of the week when the meal was consumed. It could be any of the seven days in a week (e.g., Monday, Tuesday, etc.).\n",
    "  \n",
    "time: This attribute denotes the time of the day when the meal was consumed. It's often categorized into two values: \"Lunch\" for meals consumed during the day and \"Dinner\" for meals consumed in the evening.\n",
    "\n",
    "size: This attribute indicates the size of the party dining together. It represents the number of people included in the bill.\n",
    "\n",
    "There were a few limitations of the data given that some identifying attributes that impact how much a person tips is based on age and race of the customer. Additionally, the sex of the waiter would be important to note to see if the tip given would be impacted on if the customer was a male and the waitress was a female. Another limitation is the small number of customers/rows in our dataset. We had a little less than 250 rows which is not ideal for training and testing. The type of restaurant, such as if it is a dinner or a sports bar and grille, is also not included. This is important information because that also plays a role on how much is being tipped as it depends on the customers that eat at those restaurants. For example, if a restaurant is higher-end, that will attract people on the wealthier side, thus they might tip more compared to customers from a lower-end restaurant. \n",
    "\n",
    " Our Approach\n",
    " \n",
    "From the features listed above, our target value was created using the tip column. Using the total_bill column, we found the percentage each tip from the customer fell into, for example, we saw if the tip was 15% of the bill or 10%. Then from this, we grouped the percent tips into groups, that is, if the percent fell into a group of 0-10%, 10-15%, 15-20%, 20-25%, or over 25%. Lastly, we encoded the groupings so our target value y consisted of either 0, 1, 2, 3, or 4s. For our predictor features, we used the remaining attributes such as the size, the day (encoded), the time (encoded), the total_bill, the smoker (encoded), and the sex (encoded). To train our data, we used the models logistic regression, decision tree classifier, and random forest classifier. We chose these as we wanted to compare what model would provide a higher accuracy score with our data, which was our way of evaluating our models. These were the classifier models we worked on for our penguin blog post, so we decided to test them with this data as well. Furthermore, taking more inspiration from the penguins blog post, we decided to also try to see if combinations of different features would affect the accuracy score for each model. We were interested in seeing what factors seemed to classify the tips. As mentioned, we evaluated our models based on the accuracy score and had our testing set be 20% of our data. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We started with a dataset with a little under 250 rows. We split this 80/20 into both our training and test data. After training and running our models our results for every model’s testing data set did not reach 50% accuracy. To make sure our data was not being overfitted, we found the base rate of the data, and it turned out to be about 39% accurate. If our testing results were performing better than this, then we would not have cases of overfitting and our models, given the data, despite being below 50%, would be implemented correctly. \n",
    "\n",
    "For example, with logistic regression, our training data gave us a score of 45.1% accuracy. This is higher than our base rate, 39%, but still not ideal accuracy. After training, we ran logistic regression on our testing data and still achieved a higher accuracy score than the base rate, this time getting a score of 42.8%. Since our data set is small, we can see a little bit of overfitting to the training data, but nothing too significant. We then ran logistic regression, this time implementing the best combinations of our columns, this gave us an accuracy of 44.6% with our training data. When we then applied this to our testing data, we obtained an accuracy score of 34.6%. Here, the combinations improved the score of our training data but decreased the accuracy score of our testing data. This is possibly due to the overfitting of the data. \n",
    "\n",
    "With our second model, the decision tree classifier, we got the best score of about 43.1% accuracy on the training data with it being found at depth 2. This is a lower training accuracy than logistic regression’s score, but it is still above our 39% base rate. On the testing data, the accuracy increased compared to the training data, which resulted in about a 43.2% accuracy rate found at the first depth. This score accuracy was also above the base rate, but still not ideal. Next, we ran the algorithm to find the best combinations of our training data columns and found that the best columns were the total bill, size, and day encoded columns at depth five with an accuracy of about 44.6%. When we ran these best columns through to be fitted and scored on the training data, we got an accuracy of about 77.4%, which resulted in being the best score we got for the entire models. This was higher than running the model without combinations on the training data, which was a positive result. However, the jump from 44.6% to 77.4% lets us know there is overfitting in our data because this significant jump did not occur in the testing combinations data. For example, in the testing data column combinations, we found the best columns were also total bill and sex encoded at depth nine with an accuracy score of about 47.2%. When we fitted and scored the best columns, we got an accuracy score of about 32.7%, which is significantly lower than the training combination result and below the base rate. Thus, there is overfitting in the data due to the smaller size of the dataset.\n",
    "\n",
    "Lastly, we implemented a Random Forest Classifier to see if that would improve our prediction score. Here, our testing data gave us an accuracy score of 44.9%, which is right around the scores we had seen from our other models. We then implemented the model on the training data with combinations and received an accuracy score of 44.6%. In this model, combinations did not help to improve the accuracy score on training data. We then applied this model to the testing data and saw an accuracy score of 34.7% which once again s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concluding Discussion\n",
    "\n",
    "Our project was able to improve the base rate prediction score on all three of our implementations.In terms of our planned deliverables, we were able to produce a well-documented Juniper notebook with code that runs without errors. Our final project has both graphs and a research component. We were most successful in staying on topic and adhering to the timeline we outlined in the project proposal. We were able to complete our weekly assignments and, therefore, produced all the code that we had envisioned, even if the outcome wasn’t quite what we had hoped. \n",
    "Unfortunately, we were not able to complete our own implementation of Logistic regression. We spent most of our time debugging and working on that Python block but could not get the code working on time. If we were to continue the project, our first priority would be to modify the Python package without our logistic regression. \n",
    "Regarding alternate definitions of success, Daniela and I were successful in learning more about implementing these models. Our coding speed increased exponentially from the first week to the last. Originally, we had to think through what we wanted our code to accomplish and then refile past blog posts, notes, and the internet to find out how to start. By the end, we were able to think through what the code needed to do and start implementing it within the same sitting. This process is probably even more noticeable through debugging. At the beginning of the project, even identifying the problem took lots of time and probably several office or peer help hours. However, by the end, we were able to look at an error message or discrepancies in outcomes and identify what was wrong and how to correct it on our own (mostly).\n",
    "As I mentioned in our presentation, our biggest limiting factor was our data. The data we chose was a very small sample, which led to issues within our project, like overfitting and low prediction scores. With a more robust data set, both in terms of rows (our data points gathered) and columns (variables that might have affected tipping behavior), I think we would see a major increase in our prediction scores. Empirically, variables such as the tipper's age or the server's race have been found to influence tipping behavior significantly (Lynn et al., 2008), . There is also empirical evidence on how tips are higher on weekends and female servers receive higher percent tips than their male counterparts (Lynn, 2000). These variables are represented in our data, so it would be interesting to see if combining all these factors would increase our prediction score. However, it is risky to invite data about race, age, and even sex because it allows for bias to seep into the data. In the articles we examined, influential factors such as gender and mealtime significantly shaped tipping behavior, both of which were encompassed within our dataset. However, our data lacked robustness, failing to encompass other crucial variables such as the age of the patron (Jewell, 2008). Moreover, prior research hash highlighted the necessity for more contextual data, including the mood and attitude of both the waiter and the patron (Lynn & Simons, 2000). Regrettably, our dataset offered a narrow perspective on tipping behavior, focusing solely on server attributes. If replicated, it would be advantageous to augment the dataset with information regarding the patron and the restaurant, thus providing a more comprehensive understanding of tipping dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Contributions Statements\n",
    "\n",
    "Daniela:\n",
    " For the source code, Lenox and I did paired programming where we both coded the project while we were together. We took turns with one person typing and the other walking the typer through what we were coding. There were times we worked apart to do visualizations or debugging and for that, I did the first visualization where the graph shows the correlation between the size and total bill based on the time the customer went to eat at the restaurant. I also worked on part of the formation for the last graph depicting the total bill by party size and gender. Furthermore, my laptop would have issues loading the code at times, so we worked from Lenox’s computer a few times too. For debugging, while at times it was done separately, we often met to go to office hours to get help on them if we could not figure it out. For the blog post, I wrote the abstract which we had thought of together previously, then wrote the value statement, the materials and methods, and finally wrote the results together with Lenox. For the final presentation, we split the slides evenly so each of us did two slides. I worked on the “About the Project” and the “Results of Testing Data” slides. \n",
    "\n",
    "\n",
    "Lenox: \n",
    "For our project, we split up the workload evenly between the two of us. For the presentation, we split it down the middle each doing two slides. I did the slide explaining our approach to the data and what models we implemented as well as the slide that explained our results and offered improvement if the project was to be replicated. For the coding portion, Daniela and I met 3-5 times a week for 2 hours session to do pair coding. Due to merging issues early on, we took turns with one person physically coding and the other looking for old blog posts and notes to help out. We did some coding on our own; although the majority of it took place together. I did the last three visualizations of the data in the visualization section and I read all the academic journals for this project, writing up the background section at the bottom. Because I was working with the empirical data for this project. I wrote both the introduction section and the conclusion for the project write up. I also made the bibliography file, since I had access to the sources.  Daniela and I wrote the results sections together (as well as this section of course). \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personal Statement\n",
    "\n",
    "This project has taught me more than the blog posts combined. Working with data for a long time allowed me to really understand what our data was telling me; therefore, affording more time about what to do with it and decide how I want it to be implemented. Implementing logistic regression from scratch, really helped me to understand what exactly logistic regression does and the different components it needs to function. I also feel like I have a better mathematical grasp of different machine learning models that we implemented in our project, like what a random forest classifier or a decision tree classifier does. I think the most helpful portion of this project was understand how data sets works and what goes into “cleaning a data set”. I really enjoyed manipulating columns and encoding qualitative data to have the data be able to fit into our models. This also made the visualization section of the project, much easier because I was able to fully understand our data. \n",
    "\n",
    "I think we did a good job working with the data we had. Although the results were far from what we had hoped, we spent a lot of time on the code. Even if it doesn’t show, and there was a large learning curve when we were working with our data. We were able to work so much faster and accomplish so much more in a sitting by the end of the project. Our project does a good job implementing  the different models that we have seen in class, even if they are a little more simplistic. I wish that we had more time to get our own version of logistic regression working on our data set, but we just didn’t have the time. I also would have loved to see a higher accuracy score, but I think that is more at fault of the data rather than our implementation of it. \n",
    "\n",
    "I had never really worked with data (or linear algebra or python!) so this class and this project carries limitless applications for me. I now feel much more confident pursuing a career that works with data, and as you are sure, this opens so many doors for me. Also as AI prevalence increases, I think it is so important to have a background in machine learning, and I know get to sound smart when I talk about neuroautoencoders! \n",
    ". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "\n",
    "Cho, Sun Bai. “Factors Affecting Restaurant Consumers’ Tipping Behavior.” Journal of the Korean Society for Quality Management, vol. 42, no. 1, 31 Mar. 2014, pp. 15–32, doi:10.7469/jksqm.2014.42.1.015. \n",
    "\n",
    "Jewell, Cassie N. “Factors Influencing Tipping Behavior in a Restaurant.” Psi Chi Journal of Psychological Research, vol. 13, no. 1, 2018, pp. 38–48, doi:10.24839/1089-4136.jn13.1.38. \n",
    "\n",
    "Lynn, M. “Restaurant Tipping and Service Quality a Tenuous Relationship.” The Cornell Hotel and Restaurant Administration Quarterly, vol. 42, no. 1, Feb. 2001, pp. 14–20, doi:10.1016/s0010-8804(01)90006-0. \n",
    "\n",
    "Sanjanabasu. “Tips Dataset.” Kaggle, 14 May 2020, www.kaggle.com/code/sanjanabasu/tips-dataset. Accessed 16 May 2024. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
