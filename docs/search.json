[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/BlogPost1.html",
    "href": "posts/BlogPost1.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "import pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\n\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\n\n#Data preparation copied from assignment\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\n\n# important import statements to help visualize the data\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n# Setting up data evualtions\ndef evaluate_features(features, X, y):\n    clf = RandomForestClassifier()  \n    scores = cross_val_score(clf, X[features], y, cv=5, scoring='accuracy')\n    return np.mean(scores)\n\nSetting up cross valadation score, establishing my classifier as a random object with no paramenters. CV is the amount of time we cross-validate and then return our mean scores\n\n# Combination copied from assignemnt\nfrom itertools import combinations\n\n# these are not actually all the columns: you'll \n# need to add any of the other ones you want to search for\nall_qual_cols = [\"Clutch Completion\", \"Sex\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)']\n\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = qual_cols + list(pair) \n    print(cols)\n    # you could train models and score them here, keeping the list of \n    # columns for the model that has the best score. \n\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Flipper Length (mm)']\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Depth (mm)', 'Flipper Length (mm)']\n['Sex_FEMALE', 'Sex_MALE', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n['Sex_FEMALE', 'Sex_MALE', 'Culmen Length (mm)', 'Flipper Length (mm)']\n['Sex_FEMALE', 'Sex_MALE', 'Culmen Depth (mm)', 'Flipper Length (mm)']\n\n\n“cols” was just for visualizing how to combine column, the training and test columns will be run on the variable “predicted colmns which includes the columns we haven’t dropped, culmen length and culmen depth. Cols above is compare all the data points across species inorder to produce the pair plot below\n\n# Combine quantitative features with the target variable for visualization\npenguins_explore = train[['Species', 'Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']]\n\n# Plot pairplot\nsns.pairplot(penguins_explore, hue='Species')\nplt.title('Pairplot of Penguin Features')\n\nplt.xlabel('Feature Values')  # X-axis label\nplt.ylabel('Feature Values')  # Y-axis label\nplt.legend(title='Species')  # Legend title\nplt.show()\n\n/Users/lenoxherman/anaconda3/envs/ml-0451/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/Users/lenoxherman/anaconda3/envs/ml-0451/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/Users/lenoxherman/anaconda3/envs/ml-0451/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/Users/lenoxherman/anaconda3/envs/ml-0451/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nNo artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n\n\n\n\n\n\n\n\n\nSeaborn’s pairplot feature shows us different features across different penguin species. It is a good tool to explore relationships between multiple variables and to visualize the data to make comparisons so we can see what characteristics contribute to distunguishing between species. In this case, the pairplot is applied to the penguins_explore dataframe, which includes the species of penguins and quantitative features such as culmen length, culmen depth, flipper length, and body mass.\nEach scatterplot in the grid represents the relationship between two quantitative variables, with each point representing a penguin. The histograms along the diagonal show the distribution of each individual variable. The different colors in the graph represent the different species of penguin.\n\n# Plot swarm plot\nplt.figure(figsize=(10, 6))\nsns.swarmplot(x='Species', y='Culmen Length (mm)', data=train)\nplt.title('Distribution of Culmen Length by Species')\nplt.xlabel('Species')\nplt.ylabel('Culmen Length (mm)')\nplt.show()\n\n/Users/lenoxherman/anaconda3/envs/ml-0451/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/Users/lenoxherman/anaconda3/envs/ml-0451/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n\n\n\n\n\n\n\n\n\nAbove is a swarmplot outlining the how individual data points are distributed across different categories. This plot shows the distribution of culmen length across different species. This graph can help visualize the density of data point and determine the frequency and provide context for data points like the mean or mode.\n\nsummary_table = train.groupby('Species').agg({'Culmen Length (mm)': 'mean',\n                                              'Culmen Depth (mm)': 'mean',\n                                              'Flipper Length (mm)': 'mean',\n                                              'Body Mass (g)': 'mean'}).reset_index()\nsummary_table\n\n\n\n\n\n\n\n\nSpecies\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\n\n\n\n\n0\nAdelie Penguin (Pygoscelis adeliae)\n38.970588\n18.409244\n190.084034\n3718.487395\n\n\n1\nChinstrap penguin (Pygoscelis antarctica)\n48.826316\n18.366667\n196.000000\n3743.421053\n\n\n2\nGentoo penguin (Pygoscelis papua)\n47.073196\n14.914433\n216.752577\n5039.948454\n\n\n\n\n\n\n\nThe summary table shows us mean of each category for each specie so we can easily compare quantitative data. This table can help us to compare specific features across different species of penguin.\n\n#Multi-way classification, copied from assginment\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC\n\n\n#Data preparation \nX_train, y_train = prepare_data(train)\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\n\n# Feature selection\nquantitative_features = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)'] \nqualitative_feature = ['Sex']\n\n# Train and test models\nclassifiers = {\n    \"Logistic Regression\": LogisticRegression(),\n    \"Random Forest\": RandomForestClassifier(),\n    \"Support Vector Machine\": SVC()\n}\n\n# this counts as 3 features because the two Clutch Completion \n# columns are transformations of a single original measurement. \n# you should find a way to automatically select some better columnMu\n# as suggested in the code block above\n# cols = [\"Flipper Length (mm)\", \"Body Mass (g)\", \"Clutch Completion_No\", \"Clutch Completion_Yes\"]\n\n  \n\nAbove we prepared the data preparing the data and then preforming a train_test spilt\n\n#Test- train split \nfrom sklearn.model_selection import train_test_split\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\n\n\npredictor_cols = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\"]\ntarget_col = \"Species\"\n\nAbove we chose our features that we are going to apply to the test data. For this model we want to correctly predict specie 100% of the time based on culmen length and depth.\n\nLR = LogisticRegression()\nLR.fit(X_train[predictor_cols], y_train)\nLR.score(X_train[predictor_cols], y_train)\nLR.coef_\n\narray([[-0.87699872,  1.93957404],\n       [ 0.2923175 ,  0.3240132 ],\n       [ 0.58468122, -2.26358723]])\n\n\n\n# Column combinations \nfrom itertools import combinations\n\n# these are not actually all the columns: you'll \n# need to add any of the other ones you want to search for\nall_qual_cols = [\"Clutch Completion\", \"Sex\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)']\n\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = qual_cols + list(pair) \n    print(cols)\n\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Flipper Length (mm)']\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Depth (mm)', 'Flipper Length (mm)']\n['Sex_FEMALE', 'Sex_MALE', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n['Sex_FEMALE', 'Sex_MALE', 'Culmen Length (mm)', 'Flipper Length (mm)']\n['Sex_FEMALE', 'Sex_MALE', 'Culmen Depth (mm)', 'Flipper Length (mm)']\n\n\nAgain, above demonstrates differnt combinations of features, even though we don’t apply these to our test data.\n\nfrom statistics import mean\n\n\n# LR.fit(X_test, y_test)\n# LR.score(X_test, y_test)\npreds = LR.predict(X_test[predictor_cols])\nprint(y_test == preds)\n\n[ True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True]\n\n\nAbove you can see that we were able to predict specie based on culmen length and depth with 100% accuracy!"
  },
  {
    "objectID": "posts/WomeninDataScience.html",
    "href": "posts/WomeninDataScience.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "WOMEN IN DATA SCIENCE BLOG POST\nDespite significant advancements in feminist movements, women remain conspicuously underrepresented in fields such as computing, mathematics, and engineering, which not only affects those within the industry but also the industry itself. Diversity fosters informed decision-making and sparks creativity. However, the current representation of women in STEM careers mirrors that of the 1960s, despite increased opportunities and educational access. This disparity, particularly in engineering, stems from historical shifts in the culture surrounding computing and subsequent academic requirements that disadvantage women and marginalized groups. To address this, efforts spotlighting the achievements of women in STEM are crucial. The Women in Data Science Conference that I attended, did just this. Highlighting women working with data in a variety of fields, such as political science, geography, engineering, and computer science the conference made space to discuss the different avenues women have taken with working with data. Additionally, the conference featured an alumni panel to give insight to Middlebury female alums now working in STEM fields. I really enjoyed this section as there is always a gap between education in college and success in the career world, and I enjoyed talking to alums, both recent and no0t so recent about how they used data science to make that jump.\nEven though we got the opportunity to speak with women in data related careers, these industries overall lack female representation. When industries lack proper diversity, perspectives become skewed, hindering unbiased innovation “The United States simply can’t afford to ignore the perspectives of half the population in future engineering and technical designs” (3. Corbett and Hill, 2015). Without diversity and representation in STEM industries, “everyone misses out on the novel solutions that diverse participation brings”(8, Corbett and Hill, 2015). Sometimes for non-diverse groups, the issue isn’t generating the “wrong” or unoptimal solution, its misidentifying the problem altogether.\nRight now, 26% of the population in STEM careers are women. This is an identical representation to STEM as the 1960s, despite the increased opportunity and education of women in STEM. Engineering is the most sex-segregated profession; however, compared to other profession such as lawyers or doctors, the gap between male engineers and female is exponentially wider. In the 1960s, engineering was a new field in need of workers, so it attracted men and women alike. However, when the personal computer was developed in the 80s, it created a hobbyist culture around computers, creating a gamer subculture that became dominated by men. Given the increasingly prevalence of computers both in the home and at work, colleges added increasingly stringent requirements for the computer science major. These additional requirements disproportionately disadvantaged women and people of other marginalized groups who were entering college with less math and programming experience.\nBreaking down barriers and challenging the underrepresentation of women in these fields, can be done by events that spotlighting the achievements of women in STEM, like this panel. Its important to combat workplace hostility towards women, as they are leaving STEM based jobs at a much higher rate than men. By providing visible role models, challenging stereotypes, and building support networks, these events inspire and empower women to pursue careers in STEM. They also advocate for change by raising awareness of systemic issues such as gender bias in hiring and promotion processes. By inspiring future generations of girls and students, these events help to create a more inclusive and diverse STEM community, ultimately contributing to greater gender equality in these fields.\nThis need for diversity within disciplines, extends beyond the STEM communities. Just as the STEM industry grapples with the challenge of inclusively, Amy Yuen’s examination of the Security Council sheds light on the complexities of achieving equal representation in influential decision-making bodies, like the United Nations. These insights show the importance of addressing systemic barriers and promoting diversity to create more inclusive environments conducive to progress and equitable outcomes. Amy Yuen is political science professor, who shared with us how she utilized data and data modeling to determine if the UN security council was “democratic” and offered equal representation. She first shared some necessary background information about the council, describing how there are 5 core countries with veto power who do not move off the council, but 10 other seats in which countries campaign for based on region. Despite the obvious lack of democratic voting within the council, Yuen’s focus was on evaluating the issue of equal representation. Each country holds a rotating elected seat for a month, and Yuen measured success in terms of their output during this tenure. Interestingly, she discovered that factors such as a nation’s wealth or political policies did not significantly impact their monthly output. Instead, she found that sponsorship played a pivotal role in determining the level of output on the council. Despite some countries like Japan or Brazil frequently serving on the council, Yuen noted close to equal representation among rotating elected members.\nSimilarly, Sarah M Brown, our keynote speaker, took a broader approach in investigating equal representation. She came all the way up from the University of Rhode Island to talk to us about the ethics of machine learning and how we can create systems that accurately represent society’s composition. As we are using machine learning more and more, specifically developing machine learning for sociotechnical systems, we need to direct our focus to making machine learning more fair and evaluate the context in which we create these systems.\nHer presentation started off by defining data science as equal parts computer science, stats, and domain expertise. Contrary to common practice, she emphasized the criticality of integrating domain expertise from the outset, rather than merely consulting domain experts later in the process. Contextualizing data, she argued, is key to unlocking solutions to STEM-related challenges. Expounding on this, she presented three fundamental “keys” that have shaped her work. However, she argued that it is important to contextualize this data, and pull upon non computer science or math backgrounds to unlock the keys to solving STEM related issues. The rest of the presentation was an exploration of three “keys” that have helped to unlock her work.\nHer first key was introduced back in 2004 in her high school social studies course. Her teacher described the need to use context to decipher primary sources. Drawing parallels to data as primary sources, Brown stressed the necessity of contextual understanding in deciphering, cleaning, and implementing data effectively. Her second key highlighted the social nuances and disciplinary norms inherent in different fields. She emphasized the need to situate data and models within the framework of the relevant discipline to ensure accurate interpretation and application. As a psych major, I particularly enjoyed this part of the talk. My interest is where the intersect of these two disciplines lie. My “domain skills” are being able to connect people and social leadership with data models and computer science, which can be isolating at times. The last “key” she mentioned was to meet people where they are. She recognized the power of precedent in shaping attitudes towards innovation and change. Using examples, she illustrated the challenges in prioritizing fairness over accuracy, urging for creative solutions rather than mere mathematical refinement.\nShe briefly introduced the concept of “algorithmic reparations,” which is something I had never heard before. Brown provocatively challenged the prevailing notion that accuracy must always take precedence over fairness, highlighting the need for a shift in perspective within the data science community. From a psychological standpoint, she emphasized the imperative of creative thinking in addressing these ethical dilemmas, signaling a departure from traditional approaches grounded solely in mathematical optimization. She ended the lecture on a positive note, that while we are creating machine learning systems faster than we are auditing them, society is becoming increasingly vigilant in privatizing non-biased systems.\nDr. Jessica L’roe, a female professor at Middlebury, continued to emphasize the importance of context within research like Professor Brown, drawing from her own study on deforestation and afforestation in various regions of Africa and their impacts on local communities. Employing a multifaceted approach, she collected both qualitative and quantitative data, enriching numerical findings with narratives from the local populace. One notable observation she shared was the rising population of smallholder farmers around a national park in Uganda, coinciding with an increase in tree planting activities. Looking deeper into the dynamics, she uncovered that non-local landowners were primarily responsible for the tree planting initiatives, often planting non-native species. Another intriguing aspect explored was the intergenerational changes in land parcel sizes and their implications on local livelihoods. Mothers in the area were interviewed and confessed that they were prioritizing education over agricultures for the children, because they feared that there would not be available land to farm. This nuanced examination highlights the significance of considering social dynamics alongside environmental changes and data in understanding complex issues like deforestation and community resilience.\nLaura Biester was our last keynote speaker and offered a different perspective, focusing more on training models to a data set. She presented on her research on computational linguistic models of mental health. Shifting the focus towards training models with specific datasets derived from public internet forums like Twitter and Reddit, Biester explored the utilization of language, particularly the use of first-person pronouns, as a measure of decreased mental health, among individuals with depression. However, Biester also addressed the challenges associated with accessing high-quality data due to privacy concerns, emphasizing the need for more representative datasets. I had never heard of natural language processing, so I found her talk very interesting. because it also once again combined my interests of psychology and computer science. Her model discovered that natural language models do a better job of capturing emotions, and manifested depressive symptoms, while linear regression models focus more on discussion of overall mental health and medication. Through her investigation, she uncovered the potential of out-of-domain datasets to test the generalizability of trained models, paving the way for a more holistic understanding of depression, emotions, and relationships through language processing techniques.\nIn conclusion, achieving gender equality and diversity in STEM fields requires concerted efforts to challenge systemic biases and provide support for underrepresented groups. By recognizing the value of diversity and promoting inclusive representation, industries can foster innovation and creativity while ensuring equitable opportunities for all. The insights shared by various speakers, spanning disciplines from political science to linguistics, to geography highlight the multidimensional nature of the issue and all the ways that data can be explored and utilized towards a passion. Moving forward, I learned that continued education, contextualizing data and systemic reform are essential to create a more inclusive and equitable future for women both in and out of STEM professions."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Second Post\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nTimnit Gebru\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nHello Blog\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  }
]